{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de filtrado\n",
    "\n",
    "Este notebook, by [Felipe Alonso Atienza](www.linkedin.com/in/felipe-alonso-atienza)\n",
    "\n",
    "En este notebook se revisarán los conceptos de:\n",
    "\n",
    "1. Métodos de filtrado para regresión\n",
    "2. Métodos de filtrado para clasificación\n",
    "3. Métodos de filtrado en un problema realista\n",
    "\n",
    "Primero cargamos librerías y funciones necesarias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Métodos de filtrado para regresión\n",
    "\n",
    "Vamos a analizar los métodos de [filtrado](http://scikit-learn.org/stable/modules/feature_selection.html) para regresión:\n",
    "\n",
    "* [f_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)\n",
    "* [mutual_info_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression)\n",
    "\n",
    "mediante un ejemplo sencillo.\n",
    "\n",
    "### Ejemplo \n",
    "Se tienen tres variables $x_1, x_2,x_3$, las cuales son variables aleatorias que se distribuyen uniformemente en el intervalo $[0,1]$. La salida depende de estas variables de la forma  \n",
    "\n",
    "$$y = x_1 + \\sin{(6\\pi x_2)} + 0.1\\mathcal{N}(0, 1),$$\n",
    "\n",
    "Esto es:\n",
    "\n",
    "* $y$ depende linealmente de $x_1$\n",
    "* $y$ depende no linealmente de $x_2$\n",
    "* $y$ no depende de $x_3$\n",
    "\n",
    "Por tanto, $x_3$ es una variable irrelevante para $y$. Veamos qué nos dicen nuestros test de filtrado de selección de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este ejemplo, tomado de:\n",
    "# http://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py\n",
    "\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(1000, 3)\n",
    "y = X[:, 0] + np.sin(6 * np.pi * X[:, 1]) + 0.1 * np.random.randn(1000)\n",
    "\n",
    "f_test, _ = f_regression(X, y)\n",
    "f_test /= np.max(f_test)\n",
    "\n",
    "mi = mutual_info_regression(X, y)\n",
    "mi /= np.max(mi)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.scatter(X[:, i], y, edgecolor='black', s=20)\n",
    "    plt.xlabel(\"$x_{}$\".format(i + 1), fontsize=14)\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"$y$\", fontsize=14)\n",
    "    plt.title(\"F-test={:.2f}, MI={:.2f}\".format(f_test[i], mi[i]),\n",
    "              fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Métodos de filtrado para clasificación\n",
    "\n",
    "Vamos a analizar los mismos métodos de [filtrado](http://scikit-learn.org/stable/modules/feature_selection.html) que en el caso de regresión, aplicados ahora para distintos problemas de clasificación:\n",
    "\n",
    "* [f_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif)\n",
    "* [mutual_info_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)\n",
    "\n",
    "## 2.1 Problema de clasificación linealmente separable\n",
    "\n",
    "En este problema, la variable $x_1$ define un problema linealmente separable y constituye la variable informativa. $x_2$ representa una variable redundante, mientras que $x_3$ y $x_4$ son variables ruidosas (no aportan información).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example: linearly separable problem\n",
    "np.random.seed(0)\n",
    "\n",
    "# -- parameters\n",
    "N      = 1000\n",
    "mu     = 2      # CHANGE THIS VALUE\n",
    "sigma1 = 1      # CHANGE THIS VALUE\n",
    "sigma2 = 5      # CHANGE THIS VALUE\n",
    "\n",
    "# -- variables auxiliares\n",
    "unos  = np.ones(int(N/2))\n",
    "rand2 = np.random.randn(int(N/2),1)\n",
    "\n",
    "# -- features\n",
    "y  = np.concatenate([-1*unos,unos]) \n",
    "X1 = np.concatenate([-mu + sigma1*rand2,mu + sigma1*rand2])\n",
    "X2 = sigma2*np.random.randn(N,1) - 3*X1\n",
    "\n",
    "X3 = 2*np.random.randn(N,1)\n",
    "X4 = np.random.rand(N,1)\n",
    "\n",
    "X  = np.hstack((X1,X2,X3,X4))\n",
    "\n",
    "#--- do some plotting\n",
    "plt.figure(figsize=(12, 14))\n",
    "for i in range(4):\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    plt.hist(X[y<0,i],bins=20, normed=True, alpha=0.5, label='-1',color='b')\n",
    "    plt.hist(X[y>0,i], bins=20, normed=True, alpha=0.5, label='+1',color='r')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(\"$x_{}$\".format(i + 1), fontsize=18)\n",
    "#pyplot.show()\n",
    "\n",
    "#plt.figure(figsize=(18, 5))\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.scatter(X1,X2,c=y,cmap=cm_bright)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos los métodos de filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "\n",
    "featureNames = ['x1','x2','x3','x4']\n",
    "\n",
    "# do calculations\n",
    "f_test, _ = f_regression(X, y)\n",
    "f_test /= np.max(f_test)\n",
    "\n",
    "mi = mutual_info_regression(X, y)\n",
    "mi /= np.max(mi)\n",
    "\n",
    "# do some plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(range(X.shape[1]),f_test,  align=\"center\")\n",
    "plt.xticks(range(X.shape[1]),featureNames)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('Ranking')\n",
    "plt.title('$F-test$ score')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(range(X.shape[1]),mi,  align=\"center\")\n",
    "plt.xticks(range(X.shape[1]),featureNames)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('Ranking')\n",
    "plt.title('Mutual information score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO:** Modifica los parámetros *mu*, *sigma1*, y *sigma2* y analiza sus efectos en las representaciones anteriores.  ¿Qué variable puedes considerar relevante?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Problema de clasificación no linealmente separable\n",
    "\n",
    "Vamos a analizar el problema XOR, definido por las variables $x_1$ y $x_2$. Añadimos además dos variables relevantes $x_3$ y $x_4$, con capacidad discriminatoria y que por tanto pueden ayudar a mejorar las prestaciones del problema de clasificación bajo estudio. Por último, se incluyen 20 variables ruidosas irrelevantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# -- parameters\n",
    "N     = 1000\n",
    "mu    = 1.5      # Cambia este valor\n",
    "sigma = 1      # Cambia este valor\n",
    "\n",
    "# variables auxiliares\n",
    "unos = np.ones(int(N/4))\n",
    "random4 = sigma*np.random.randn(int(N/4),1)\n",
    "random2 = sigma*np.random.randn(int(N/2),1)\n",
    "\n",
    "# -- features\n",
    "y = np.concatenate([-1*unos,       unos,          unos,         -1*unos]) \n",
    "X1 = np.concatenate([-mu + random4, mu + random4, -mu + random4, mu + random4])\n",
    "X2 = np.concatenate([+mu + random2,               -mu + random2])\n",
    "\n",
    "X3 = 3*(X1+X2) + np.sqrt(2)*np.random.randn(N,1)\n",
    "X4 = 2*np.square((X1+X2)) + np.sqrt(2)*np.random.randn(N,1)\n",
    "\n",
    "E  = 2*np.random.randn(N, 20) # noisy variables\n",
    "\n",
    "X  = np.hstack((X1,X2,X3,X4,E))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "\n",
    "plt.scatter(X1,X2,c=y, cmap=cm_bright)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(2, 2, i + 2)\n",
    "    plt.hist(X[y<0,i+1],bins=20, normed=True, alpha=0.5, label='-1',color='b')\n",
    "    plt.hist(X[y>0,i+1], bins=20, normed=True, alpha=0.5, label='+1',color='r')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(\"$x_{}$\".format(i + 2), fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureNames = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14',\n",
    "                'x15','x16','x17','x18','x19','x20','x21','x22','x23','x24']\n",
    "\n",
    "\n",
    "# do calculations\n",
    "f_test, _ = f_regression(X, y)\n",
    "f_test /= np.max(f_test)\n",
    "\n",
    "mi = mutual_info_regression(X, y)\n",
    "mi /= np.max(mi)\n",
    "\n",
    "# do some plotting\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(range(X.shape[1]),f_test,  align=\"center\")\n",
    "plt.xticks(range(X.shape[1]),featureNames, rotation = 45)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('Ranking')\n",
    "plt.title('$R^2$ score')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(range(X.shape[1]),mi,  align=\"center\")\n",
    "plt.xticks(range(X.shape[1]),featureNames, rotation = 45)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('Ranking')\n",
    "plt.title('Mutual information score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO:** Modifica los parámetros *mu*, y *sigma* y analiza sus efectos en las representaciones anteriores.  ¿Qué variable puedes considerar relevante?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Métodos de filtrado sobre problema realista\n",
    "\n",
    "Vamos a aplicar los métodos de filtrado sobre la base de datos  de viviendas [House Sales in King COunty, USA](https://www.kaggle.com/harlfoxem/housesalesprediction)\n",
    "\n",
    "Recordamos que para cada vivienda, se tienen los siguientes atributos, características o features:\n",
    "\n",
    "| Atributo | descripción |\n",
    "| :- |:- |\n",
    "|*id*| identificador de la vivienda|\n",
    "| *date*| fecha\n",
    "| *price*| precio\n",
    "| *bedrooms*| número de habitaciones\n",
    "| *bathrooms*| número de baños/aseos\n",
    "| *sqtf_living*| superficie habitable (en pies al cuadrado)\n",
    "| *sqft_lot*| superficie de la parcela (en pies al cuadrado)\n",
    "| *floors*| número de plantas\n",
    "| *waterfront*| indica si la vivienda tiene acceso a un lago\n",
    "| *view*| tipo de vista (variable numérica)\n",
    "| *condition*| condición de la vivienda (variable númerica)\n",
    "| *grade*| medida de la calidad de la construcción (variable numérica)\n",
    "| *sqft_above*| superficie por encima del suelo (en pies al cuadrado)\n",
    "| *sqft_basement*| superficie del sótano (en pies al cuadrado)\n",
    "| *yr_built*| año de construcción de la vivienda\n",
    "| *yr_renovated*| año de renovación de la vivienda\n",
    "| *lat*| latitud de la parcela\n",
    "| *long*| longitud de la parcela\n",
    "| *sqft_living15*| superficie habitable promedio de los 15 vecinos más cercanos \t\t\t\t\n",
    "| *sqft_lot15*| superficie de la parcela promedio de los 15 vecinos más cercanos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cargamos datos\n",
    "house_data = pd.read_csv(\"./data/kc_house_data.csv\") # cargamos fichero\n",
    "\n",
    "# Eliminamos las columnas id y date \n",
    "house_data = house_data.drop(['id','date'], axis=1)\n",
    "\n",
    "# convertir las variables en pies al cuadrado en metros al cuadrado \n",
    "feetFeatures = ['sqft_living','sqft_lot','sqft_above','sqft_basement','sqft_living15','sqft_lot15']\n",
    "house_data[feetFeatures] = house_data[feetFeatures].apply(lambda x: x * 0.3048 * 0.3048)\n",
    "\n",
    "# renombramos\n",
    "house_data.columns = ['price','bedrooms','bathrooms','sqm_living','sqm_lot','floors','waterfront','view','condition',\n",
    "                      'grade','sqm_above','sqm_basement','yr_built','yr_renovated','zip_code','lat','long',\n",
    "                      'sqm_living15','sqm_lot15']\n",
    "\n",
    "# añadimos las nuevas variables\n",
    "house_data['years']            = 2017 - house_data['yr_built']\n",
    "house_data['bedrooms_squared'] = house_data['bedrooms'].apply(lambda x: x**2)\n",
    "house_data['bed_bath_rooms']   = house_data['bedrooms']*house_data['bathrooms']\n",
    "house_data['log_sqm_living']   = house_data['sqm_living'].apply(lambda x: np.log(x))\n",
    "house_data['lat_plus_long']    = house_data['lat']*house_data['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = np.abs(house_data.drop(['price'], axis=1).corr())\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask,vmin = 0.0, vmax=1.0, center=0.5,\n",
    "            linewidths=.1, cmap=\"YlGnBu\", cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos el DataFrame al formato necesario para scikit-learn\n",
    "data = house_data.as_matrix() \n",
    "\n",
    "y = data[:,0:1]     # nos quedamos con la 1ª columna, price\n",
    "X = data[:,1:]      # nos quedamos con el resto\n",
    "\n",
    "feature_names = house_data.columns[1:]\n",
    "\n",
    "\n",
    "# do calculations\n",
    "f_test, _ = f_regression(X, y)\n",
    "f_test /= np.max(f_test)\n",
    "\n",
    "mi = mutual_info_regression(X, y)\n",
    "mi /= np.max(mi)\n",
    "\n",
    "# do some plotting\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(range(X.shape[1]),f_test,  align=\"center\")\n",
    "plt.xticks(range(X.shape[1]),feature_names, rotation = 90)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('Ranking')\n",
    "plt.title('$R^2$ score')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(range(X.shape[1]),mi, align=\"center\")\n",
    "plt.xticks(range(X.shape[1]),feature_names, rotation = 90)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('Ranking')\n",
    "plt.title('Mutual information score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO:** Las variables seleccionadas, ¿concuerdan con tu intuición?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
