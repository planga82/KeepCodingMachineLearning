{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fundamentos de *Machine Learning*\n",
    "\n",
    "Este notebook, by [Felipe Alonso Atienza](www.linkedin.com/in/felipe-alonso-atienza)\n",
    "\n",
    "En este notebook se revisarán los conceptos de:\n",
    "\n",
    "1. Notación\n",
    "2. Vecinos más próximos\n",
    "3. Evaluación del modelo: entrenamiento y test\n",
    "4. Selección del modelo: validación cruzada\n",
    "5. Conceptos fundamentales de ML\n",
    "  1. Compromiso sesgo-varianza\n",
    "  2. Curvas de aprendizaje\n",
    "\n",
    "Primero cargamos librerías y funciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definimos una función para representar el resultado del ajuste\n",
    "def plot_decision_boundary(X,y,h,model):\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = .05  # step size in the mesh\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Zd = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Zd = Zd.reshape(xx.shape)\n",
    "    \n",
    "    Zp = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1] \n",
    "    Zp = Zp.reshape(xx.shape)\n",
    "    \n",
    "    # Error de clasificación\n",
    "    ypred = model.predict(X)\n",
    "    acc = accuracy_score(y,ypred)\n",
    "    \n",
    "    plt.figure(1, figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright)\n",
    "    plt.axis([x_min, x_max, y_min, y_max])\n",
    "    plt.contour(xx, yy, Zd, levels=[0], linewidths=2)\n",
    "    plt.contourf(xx, yy, Zd,cmap=cm, alpha=.5)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "    msg = 'FRONTERA DECISION\\n Acc: %0.2g' % acc\n",
    "    plt.title(msg)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright)\n",
    "    plt.axis([x_min, x_max, y_min, y_max])\n",
    "    #plt.contour(xx, yy, Zp, levels=[0], linewidths=2)\n",
    "    plt.contourf(xx, yy, Zp,cmap=cm, alpha=.5)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "    msg = 'PROBABILIDAD\\n Acc: %0.2g' % acc\n",
    "    plt.title(msg)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "# ejecute esta celda\n",
    "def miRegresionLineal(x_i,y_i,x,y,degree):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_i  = poly.fit_transform(x_i.reshape(-1, 1))\n",
    "    X_test = poly.fit_transform(x.reshape(-1, 1))\n",
    "    lr     = LinearRegression().fit(X_i,y_i)\n",
    "    \n",
    "    y_hat = lr.predict(X_i)\n",
    "    fw = lr.predict(X_test)\n",
    "    \n",
    "    error_train = np.mean(np.power(y_i-y_hat,2)) \n",
    "    error_test  = np.mean(np.power(y-fw,2)) \n",
    "    \n",
    "   # print(lr.coef_)\n",
    "    \n",
    "    return fw, error_test, error_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notación\n",
    "\n",
    "Echa un vistazo a los [datasets](http://scikit-learn.org/stable/datasets/index.html) de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Sobre el conjunto de datos anterior, indique si se trata de un problema de clasificación o de regresión, y calcule los siguientes valores:\n",
    "</div>\n",
    "\n",
    "* $N$: número de muestras\n",
    "* $d$: dimensionalidad del espacio de entrada\n",
    "* $\\mathbf{x}^{(10)}$: muestra $i=10$\n",
    "* $\\mathbf{x}_1$: característica/variable/*feature* $1$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vecinos más próximos\n",
    "\n",
    "En este notebook vamos a trabajar con el algoritmo de KNN en distintos problemas de **clasificación**.\n",
    "\n",
    "## 2.1. Medida de las prestaciones de un clasificador\n",
    "\n",
    "Por clasificador entendemos un algoritmo que, a partir de un conjunto de muestras/observaciones de entrenamiento, es capaz de identificar que identifica a qué clase (categoría) pertenece una nueva observación.\n",
    "\n",
    "Una métrica de calidad que podemos usar para medir las prestaciones de un clasificador es el **error de clasificación**\n",
    "\n",
    "$$\\textrm{Error} = \\frac{\\textrm{# muestras mal clasificadas}}{\\textrm{# de muestras total del problema}}$$\n",
    "\n",
    "* Ejemplo: problema de clasificación con dos clases $y\\in{0,1}$\n",
    "    * Etiquetas reales (*y_true*) = $[1,0,0,1,0]$\n",
    "    * Etiquetas predichas (*y_pred*) = $[0,0,1,1,0]$\n",
    "    \n",
    "    * En este caso: $$\\textrm{Error} = \\frac{\\textrm{# muestras mal clasificadas} = 2}{\\textrm{# de muestras total del problema} = 5} = \\frac{2}{5} = 0.4$$\n",
    "\n",
    "Así, el error de clasificación será un número entre 0 y 1, tal que:\n",
    "\n",
    "* $\\textrm{Error} = 0$ es el mejor valor posible (no me equivoco nada)\n",
    "* $\\textrm{Error} = 1$ es el peor valor posible (me equivoco en todas las muestras). Nota: si me equivoco en la clasificación de todas las muestras, entonces puedo interpretar que el clasificador es bueno, pero que tengo que hacer justo lo contrario de lo que me dice. El peor valor de error sería por tanto $0.5$, en el que la incertidumbre es mayor. \n",
    "\n",
    "Normalmente no se utiliza el error, sino su complementario, la exactitud o [**accuracy**](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) (Acc):\n",
    "\n",
    "$$\\textrm{Acc} = 1 - \\textrm{Error}$$\n",
    "\n",
    "y entonces:\n",
    "\n",
    "* $\\textrm{Acc} = 1$ es el mejor valor posible (no me equivoco nada)\n",
    "* $\\textrm{Acc} = 0$ es el peor valor posible (me equivoco en todas las muestras)\n",
    "\n",
    "## 2.2 Ejemplos\n",
    "\n",
    "Para analizar el comportamiento del algoritmo de K-NN, utilizaremos tres ejemplos sencillos, como mostraremos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo1\n",
    "ejemplo1 = pd.read_csv(\"./data/ex2data1.txt\", sep=\",\", header=None, names=['x1', 'x2','label'])\n",
    "ejemplo1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: ¿Habéis trabajado con pandas anteriormente?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ejemplo1['x1'], ejemplo1['x2'], c=ejemplo1['label'], cmap=cm_bright)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dice que este problema es **linealmente separable**, porque podemos trazar una recta para separar (no de forma perfecta) las dos clases (representadas en distintos colores, rojo y azul).\n",
    "* En el plano bidimensional: recta\n",
    "* En un espacio d-dimensional: hiperplano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo2\n",
    "ejemplo2 = pd.read_csv(\"./data/ex2data2.txt\", sep=\",\", header=None, names=['x1', 'x2','label'])\n",
    "\n",
    "plt.scatter(ejemplo2['x1'], ejemplo2['x2'], c=ejemplo2['label'], cmap=cm_bright)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dice que este problema es **no linealmente separable**, porque no podemos trazar una recta para separar las dos clase (representadas en distintos colores, rojo y azul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo 3: Problema XOR \n",
    "np.random.seed(0)\n",
    "\n",
    "# -- parameters\n",
    "N     = 800\n",
    "mu    = 1.5      # Cambia este valor\n",
    "sigma = 1      # Cambia este valor\n",
    "\n",
    "# variables auxiliares\n",
    "unos = np.ones(int(N/4))\n",
    "random4 = sigma*np.random.randn(int(N/4),1)\n",
    "random2 = sigma*np.random.randn(int(N/2),1)\n",
    "\n",
    "# -- features\n",
    "y3 = np.concatenate([-1*unos,       unos,          unos,         -1*unos]) \n",
    "X1 = np.concatenate([-mu + random4, mu + random4, -mu + random4, mu + random4])\n",
    "X2 = np.concatenate([+mu + random2,               -mu + random2])\n",
    "X3 = np.hstack((X1,X2))\n",
    "\n",
    "plt.scatter(X3[:,0], X3[:,1], c=y3, cmap=cm_bright)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el caso anterior, este ejemplo tampoco es linealmente separable, y se conoce como problema XOR. La ventaja del problema XOR es que conocemos cuál es la frontera de separación óptima a priori:\n",
    "\n",
    "- Clase 1, color azul: $x_1,x_2 > 0$, y $ x_1,x_2 < 0$ (cuadrantes 1 y 3)\n",
    "- Clase 2, color rojo: $x_1 < 0,  x_2 > 0$, y $x_1 > 0,  x_2 < 0$ (cuadrantes 2 y 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Entrenar el modelo \n",
    "\n",
    "Vamos a entrenar un modelo K-NN para los distintos ejemplos:\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Echa un vistazo a la [documentación](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) del modelo K-NN en sklearn\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ejemplo 1\n",
    "# preparamos los datos\n",
    "data1 = ejemplo1.as_matrix() #¡IMPORTANTE! \n",
    "X1 = data1[:,0:2]\n",
    "y1 = data1[:,-1]\n",
    "\n",
    "# creamos el modelo y ajustamos\n",
    "knnModel = KNeighborsClassifier(n_neighbors=1)\n",
    "knnModel.fit(X1,y1)\n",
    "\n",
    "plot_decision_boundary(X1,y1,0.05,knnModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Número de vecinos**\n",
    "\n",
    "Podemos modificar el número de vecinos $k$ del algoritmo k-nn implementado en scikit-learn mediante el parámetro *n_neighbors*. Por defecto, [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) toma *n_neighbors* $=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Varía el valor de *n_neighbors*, ¿qué sucede ahora?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Aplica el algoritmo K-NN sobre los ejemplos 2 y 3. ¿Qué sucedería si aplicamos sobre estos ejemplos un algoritmo de [regresión logística](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)? ¿Qué pasa si variamos el número de vecinos?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que las mejores prestaciones se obtienen cuando *n_neighbors=1*, ¿tiene sentido? ¿Estamos midiendo correctamente las prestaciones de este clasificador?\n",
    "\n",
    "# 3. Evaluación del modelo: entrenamiento y test\n",
    "\n",
    "La respuesta es claramente no. Para poder saber cómo de bien se comporta un algoritmo de machine learning, hemos de medir su capacidad de [generalización](https://en.wikipedia.org/wiki/Generalization_error), esto es, las prestaciones en muestras no vistas previamente por el clasificador. Para ello, dividimos el conjunto de entrenamiento en dos partes, entrenamiento y test, teniendo en cuenta que:\n",
    "\n",
    "<img src=\"./figuras/train_test_set_2d_classification.png\", width=300,height=300>\n",
    "\n",
    "* Utilizamos aproximadamente un 70-75% de las muestras para entrenamiento y un 30-25% para el test.\n",
    "* Ambos conjuntos han de representar la población con la misma estadística: \n",
    "    * Randomizar, esto es, reordenar para evitar orden en las muestras. (cuidado series temporales)\n",
    "    * Estratificar con respecto a una variable (normalmente la variable target), para mantener la proporción de la varible target en los conjuntos train/test.\n",
    "\n",
    "sklern nos proporciona una [función](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para dividir nuestros datos. \n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Echa un vistazo a la documentación de la función.\n",
    "</div>\n",
    "\n",
    "Vamos a probar con el primer ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "plot_decision_boundary(X_test,y_test,0.05,knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Sobre la celda anterior, varía el valor de *n_neighbors*. ¿Para qué valor se obtienen ahora las mejores prestaciones? ¿Qué sucede si eliminamos *random_state = 0* y ejecutamos varias veces la misma celda para un valor de *n_neighbors* fijo? ¿Obtenemos las mismas prestaciones? ¿Y si estratificamos?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Calcula las prestaciones del algoritmo K-NN para los ejemplos 2 y 3. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejemplo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO (AVANZADO): Representa las prestaciones del algoritmo K-NN en entrenamiento y test para distintos valores de *n_neighbors* (entre 1 y 15), utilizando el ejemplo 3. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "# inicializamos\n",
    "neighbors = range(1,15)\n",
    "acc_train = []\n",
    "acc_test  = []\n",
    "\n",
    "for n in neighbors:\n",
    "    \n",
    "    ################## tu código aquí\n",
    "    \n",
    "    \n",
    "    #################\n",
    "    \n",
    "    acc_train.append(knn.score(X_train, y_train))\n",
    "    acc_test.append(knn.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "plt.plot(neighbors,acc_train,'b',label='train')\n",
    "plt.plot(neighbors,acc_test,'r',label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('ACC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El número de vecinos que escojamos afecta significativamente a las prestaciones del algoritmo. Este parámetro es un compromiso entre los errores que cometemos (*accuracy*) y la complejidad del modelo (frontera de separación). \n",
    "\n",
    "- Cuanto menor es el número de vecinos, **más compleja** es la frontera de separación, y por tanto mayor será el sobreajuste. Potencialmente empeorará la *accuracy*.\n",
    "- Cuanto mayor es el número de vecinos, **menos compleja** es la frontera de separación y por tanto menor será el sobreajuste. Potencialmente mejorará *accuracy*.\n",
    "\n",
    "## 3.1 Conclusiones\n",
    "\n",
    "1. Si las muestras de entrenamiento son escasas (ejemplo 1), el error en test puede ser muy variable , dependiendo de las muestras incluidas en el conjunto de entrenamiento y el conjunto de test.\n",
    "\n",
    "2. Las prestaciones (en test), dependen del número de vecinos que determinan la complejidad de la frontera de separación.\n",
    "\n",
    "Teniendo en cuenta 1 y 2, ¿cómo puedo escoger el valor óptimo de *n_neighbors*?\n",
    "\n",
    "\n",
    "# 4. Selección del modelo: validación cruzada\n",
    "\n",
    "La validación cruzada (o cross-validation) consiste en subdivir el conjunto de entrenamiento en $K$ partes iguales, de tal forma que se utilizan $K-1$ para entrenar (ajustar el modelo) y el bloque $k$ restante para evaluar las prestaciones en función de los parámetros libres. Este proceso se repite $K$ veces (hasta que se barren todos los bloques) y los resultados se promedian.\n",
    "\n",
    "Por suerte, no es necesario programar estas subdivisiones, porque scikit-learn tiene un clase que realiza este trabajo por nosotros. Puedes consultarlo [aquí](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n",
    "\n",
    "Vamos a buscar el valor óptimo del número de vecinos utilizando una estrategia 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# recordemos que este es nuestro conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "nFolds = 5 #scikit-learn los llama splits\n",
    "kf  = StratifiedKFold(n_splits = nFolds, shuffle = True, random_state=0)\n",
    "\n",
    "nVecinos = range(1,16) # [1-15]\n",
    "\n",
    "# inicializamos una matriz de errores, para cada valor de n_neighbors y cada iteración del algoritmo de cross-validation\n",
    "# - tantas filas como número de folds\n",
    "# - tantas columnas como valores de alphaVector\n",
    "accMatriz = np.zeros((nFolds,len(nVecinos))) \n",
    "\n",
    "j = 0 # inicializamos contador de columnas\n",
    "for n in nVecinos:\n",
    "       \n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    \n",
    "    i = 0 # inicializamos contador de filas\n",
    "    for idxTrain, idxVal in kf.split(X_train,y_train):\n",
    "      \n",
    "        Xt = X_train[idxTrain,:]\n",
    "        yt = y_train[idxTrain]\n",
    "        Xv = X_train[idxVal,:]\n",
    "        yv = y_train[idxVal]\n",
    "        \n",
    "        knn.fit(Xt,yt)\n",
    "        accMatriz[i,j] = knn.score(Xv, yv) \n",
    "        \n",
    "        i+=1\n",
    "    j+=1\n",
    "\n",
    "accVector = np.mean(accMatriz,axis=0)\n",
    "accStd = np.std(accMatriz,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el valor óptimo\n",
    "idx = np.argmax(accVector)\n",
    "nOpt = nVecinos[idx]\n",
    "\n",
    "plt.plot(nVecinos,accVector,'-o')\n",
    "plt.plot(nVecinos[idx],accVector[idx],'rs')\n",
    "plt.title('El número óptimo de vecinos es: %d' % nOpt)\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representemos ahora la gráfica anterior con la variación (desviación estándar) de la *accuracy* en cada *fold*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nVecinos,accVector,'-o')\n",
    "plt.plot(nVecinos[idx],accVector[idx],'rs')\n",
    "plt.errorbar(nVecinos, accVector, yerr=accStd, ecolor='g')\n",
    "plt.title('El número óptimo de vecinos es: %d' % nOpt)\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damos las prestaciones reales del modelo (en test)\n",
    "knn = KNeighborsClassifier(n_neighbors = nOpt)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "print(\"accuracy: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior se puede reducir drásticamente si utilizamos [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "param_grid = {'n_neighbors':  np.arange(1, 16, 1)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), scoring= 'accuracy', param_grid=param_grid, cv = 5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score']) #¡cuidado, lo llaman test cuando es validación!\n",
    "stdvalues = np.array(grid.cv_results_['std_test_score'])\n",
    "plt.plot(nVecinos,scores,'-o')\n",
    "#plt.errorbar(nVecinos, scores, yerr=stdvalues, ecolor='g')\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"acc (test): {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ¿Cómo elegimos el algoritmo adecuado?\n",
    "\n",
    "No hay *free lunch*, ningún método/algoritmo es mejor que otro para todos los problemas (conjuntos de datos). Para entender si el algoritmo adecuado se comporta adecuadamente, hay que tener en cuenta:\n",
    "\n",
    "- Ruido en los datos (error irreducible)\n",
    "- Número de ejemplos disponibles\n",
    "- Número de características (dimensionalidad del problema)\n",
    "\n",
    "## 5.1 Compromiso sesgo-varianza\n",
    "\n",
    "Este principio permite analizar el alcance de las prestaciones (error de generalización) en tareas de aprendizaje supervisado. \n",
    "\n",
    "Supongamos que tenemos un proceso $y = g(x) + \\epsilon$, donde $\\epsilon$ representa una fuente de error irreducible (ruido en los datos). Del proceso $y$, tenemos información de un conjunto de muestras  $D = \\{x^{(i)},y^{(i)}\\}$, con $i=1,\\ldots,N$. \n",
    "\n",
    "A partir de estos datos $D$, buscamos encontrar la función $f_{\\omega}(x)$ que *mejor se ajuste* a la verdadera función $g(x)$, utilizando un algoritmo de *machine learning*. Por mejor ajuste se entiende que se quiere medir el error cuadrático medio $\\left(y - f_{\\omega}(x)\\right)^2$, tanto para el conjunto $D$, como para cualquier muestra no contenida en $D$ (capacidad de generalización). \n",
    "\n",
    "Dado que $y$ es un proceso que contiene ruido, es difícil que podamos ajustar $f_{\\omega}(x)$ a $g(x)$ de forma perfecta. Se puede demostrar que, en promedio, el error que se comete para cualquier valor de $x\\notin D$ (error de generalización), se descompone en:\n",
    "\n",
    "$$ \\textrm{error}(x) = E\\Big[\\big(y - f_{\\omega}(x)\\big)^2\\Big] = \\textrm{Bias}\\big[f_{\\omega}(x)\\big]^2 + \\textrm{Var}\\big[f_{\\omega}(x)\\big] + \\sigma^2 $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $\\textrm{Bias}\\big[f_{\\omega}(x)\\big]^2 = E\\Big[f_{\\omega}(x)\\Big]^2 - g(x)$ representa el error asociado a la simplicidad del modelo.\n",
    "* $\\textrm{Var}\\big[f_{\\omega}(x)\\big]$ representa la variabilidad del modelo frente a distintos conjuntos de entrenamiento. Pequeños cambios en el conjunto de entrenamiento pueden producir grandes errores.\n",
    "* $\\sigma^2$ es una cota al error mínimo que puedo alcanzar. \n",
    "\n",
    "Por tanto, el objetivo es buscar un algoritmo que proporcione mínimo sesgo y mínima varianza.\n",
    "\n",
    "### 5.1.1 Ejemplo\n",
    "\n",
    "Veamos con un ejemplo. Supongamos que $y = g(x) + \\epsilon$, donde:\n",
    "\n",
    "* $g(x) = \\cos{(1.5\\pi x})$, $x \\in [0,1]$\n",
    "* $\\epsilon \\sim N(0,\\sigma^2)$, $\\sigma = 0.2$\n",
    "* Disponemos del conjunto de datos $D = \\{x^{(i)},y^{(i)}\\}$, con $i=1,\\ldots,N$. \n",
    "\n",
    "Queremos estimar $g(x)$ a partir del conjunto de datos $D$ disponible. Para ello, vamos a utilizar tres funciones:\n",
    "\n",
    "* Regresión lineal orden 1: modelo **sencillo** $$f^1_{\\omega}(x) = \\omega_0 + \\omega_1 x$$ \n",
    "* Regresión lineal orden 4: modelo **intermedio** $$f^4_{\\omega}(x) = \\omega_0 + \\omega_1 x + \\omega_2 x^2 + \\omega_3 x^3 + \\omega_4 x^4$$ \n",
    "* regresión lineal orden 7: modelo **flexible** (complejo) $$f^{7}_{\\omega}(x) = \\omega_0 + \\sum_{j=1}^{7}\\omega_j x^j$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: dibuje la función $g(x)$, y el conjunto de datos $D = \\{x^{(i)},y^{(i)}\\}$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 10\n",
    "N_test  = 100\n",
    "\n",
    "# función verdadera g(x)\n",
    "x = np.linspace(0,1,N_test)\n",
    "g_x = np.cos(1.5*np.pi*x)\n",
    "\n",
    "# proceso y\n",
    "np.random.seed(0) # para asegurar reproducibilidad\n",
    "epsilon = np.random.randn(N_test) * 0.2\n",
    "y = g_x + epsilon\n",
    "\n",
    "# Datos: D = {x_i,y_i}, obtenemos una muestra\n",
    "idx = np.random.randint(0,N_test,N_train)\n",
    "x_i = x[idx]\n",
    "y_i = y[idx]\n",
    "\n",
    "# YOUR CODE HERE: dibuje la función g(x), y el conjunto de datos x_i,y_i\n",
    "########\n",
    "\n",
    "\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación representamos la salida obtenida y el error cometido para las tres funciones definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecute esta celda\n",
    "grado_polinomio = [1,4,7]\n",
    "\n",
    "#idx = np.random.randint(0,N_test,N_train)\n",
    "#x_i = x[idx]\n",
    "#y_i = y[idx]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for j,d in enumerate(grado_polinomio):\n",
    "    \n",
    "    f_k, mse, _ = miRegresionLineal(x_i,y_i,x,y,d)\n",
    "    \n",
    "    ax = plt.subplot(1, 3, j+1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    plt.plot(x,g_x,'r',label='$g(x)$')\n",
    "    plt.plot(x_i,y_i,'b.',label='muestras')\n",
    "    plt.plot(x,f_k,'g',label='$f_w(x)$')\n",
    "    plt.title('Grado: %i\\nMSE:%.2f'%(d,mse))\n",
    "    plt.legend()\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede comprobar que el modelo de orden 7 se **sobreajusta** a las muestras de entrenamiento (la función pasa por los puntos de entrenamiento), y por tanto su capacidad de generalización es muy limitada.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Descomente las líneas de código y vuelva a ejecutar la celda, ¿qué resultado obtiene ahora?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, para analizar el sesgo y la varianza de los modelos anteriores, tenemos que calcular sus prestaciones para distintos conjuntos de entrenamiento, y posteriormente calcular su media y su varianza.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: En la siguiente celda, escribe el código obtener una nuevo conjunto de datos $D = \\{x^{(i)},y^{(i)}\\}$ para cada repetición del experimento.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "grado_polinomio = [1,4,7]\n",
    "Nrepeticiones = 20\n",
    "\n",
    "# inicializamos\n",
    "mse  = np.zeros((len(grado_polinomio),Nrepeticiones))\n",
    "f_w  = np.zeros((Nrepeticiones,N_test,len(grado_polinomio)))\n",
    "np.random.seed(0)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for k in range(Nrepeticiones):\n",
    "    \n",
    "    y = g_x + np.random.randn(N_test) * 0.2\n",
    "    \n",
    "    #### YOUR CODE HERE: (~3 lines). Obten las muestras de un nuevo conjunto de entrenamiento\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####\n",
    "    \n",
    "    for j,d in enumerate(grado_polinomio):\n",
    "\n",
    "        f_k, mse[j,k], _ = miRegresionLineal(x_i,y_i,x,y,d)\n",
    "        f_w[k,:,j] = f_k\n",
    "\n",
    "        ax = plt.subplot(1, 3, j+1)\n",
    "        plt.plot(x_i,y_i,'b.',alpha=0.1)\n",
    "        plt.plot(x,f_k,'g',alpha=0.1)\n",
    "        \n",
    "\n",
    "for j,d in enumerate(grado_polinomio):\n",
    "    ax = plt.subplot(1, 3, j+1)\n",
    "    f_k = np.mean(f_w[:,:,j],axis=0)\n",
    "    \n",
    "    bias = g_x - f_k\n",
    "    var = np.var(f_w[:,:,j],axis=0)\n",
    "        \n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    plt.plot(x,g_x,'r')\n",
    "    plt.plot(x,f_k,'g',linewidth=2)\n",
    "    plt.title('Grado: %i\\nMSE: %.2f +/- %.2f\\nBIAS: %.2f VAR: %.2f'%(d,\n",
    "                                                                     np.mean(mse[j,:]),\n",
    "                                                                     np.std(mse[j,:]),\n",
    "                                                                     np.mean(bias**2),\n",
    "                                                                     np.mean(var)))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.xlim((0, 1))\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado anterior nos indica que modelos muy complejos tienden a sobreajustarse a los datos (alta varianza), mientras que modelos muy sencillos (alto sesgo), no consiguen aproximarse adecuadamente. Así, el compromiso buscar un algoritmo que tenga mínimo sesgo y mínima varianza.\n",
    "\n",
    "Así: \n",
    "\n",
    "* Para reducir el sesgo, se necesitan modelos más complejos\n",
    "* Para reducir la varianza, se necesita reducir la complejidad. Una opción es aumentar el número de muestras de entrenamiento. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO (Avanzado): Represente el error cuadrático medio (entrenamiento y test) para distintos niveles de complejidad del algoritmo de regresión lineal (distintos grados del polinomio)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "grado_polinomio = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "Nrepeticiones = 100\n",
    "\n",
    "# inicializamos\n",
    "mse_test  = np.zeros((len(grado_polinomio),Nrepeticiones))\n",
    "mse_train  = np.zeros((len(grado_polinomio),Nrepeticiones))\n",
    "np.random.seed(0)\n",
    "\n",
    "for k in range(Nrepeticiones):\n",
    "    \n",
    "    y = g_x + np.random.randn(N_test) * 1\n",
    "    \n",
    "    idx = np.random.randint(0,N_test,N)\n",
    "    x_i = x[idx]\n",
    "    y_i = y[idx]\n",
    "    \n",
    "    for j,d in enumerate(grado_polinomio):\n",
    "\n",
    "        _, mse_test[j,k], mse_train[j,k] = miRegresionLineal(x_i,y_i,x,y,d)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberías obtener algo como:\n",
    "\n",
    "<img src=\"figuras/entrenamiento_test_complejidad.pdf\", width=500,height=500>\n",
    "\n",
    "Fuente: *The Elements of Statistical Learning*\n",
    "\n",
    "Por tanto, examinando la diferencia en las prestaciones entre el conjunto de entrenamiento/validación y test, puedes saber si estás en alguna de las siguientes situaciones:\n",
    "\n",
    "* **Alto sesgo**: error de entrenamiento/validación y error en test similar, pero muy alto. Cuando esto sucede podemos\n",
    "    * Aumentar el número de variables / características\n",
    "    * Aumentar el grado del polinomio (mayor complejidad)\n",
    "* **Alta varianza**: gran diferencia entre error de entrenamiento/validación y test con un error de entrenamiento pequeño\n",
    "    * Aumentar el número de muestras de entrenamiento\n",
    "    * Reducir el número de variables / características\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.2 Número de ejemplos disponibles\n",
    "\n",
    "De la discusión anterior podemos pensar que cuando tratamos con un problema muy complejo, utilizar más muestras de entrenamiento siempre nos va a ayudar, así que deberíamos dedicar muchos esfuerzo en conseguir muchos ejemplos. Pues bien, esto no es del todo cierto, y para ello podemos representar las curvas de aprendizaje o *learning curves*, las cuales representan la evolución de las prestaciones de un algoritmo supervisado (entrenamiento/validación y test) frente al número de muestras utilizadas. \n",
    "\n",
    "Estas curvas tienen un aspecto como\n",
    "\n",
    "<img src=\"figuras/learning_curves.png\", width=1000,height=500>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: ¿Podrías decir cuál de las curvas anteriores se corresponde con un problema de alto sesgo/varianza?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Dimensionalidad\n",
    "\n",
    "Hace referencia al número de características que podemos utilizar en un problema de aprendizaje automático. Hay que tener en cuenta el principio de la [Maldición de la dimensionalidad](https://en.wikipedia.org/wiki/Curse_of_dimensionality).\n",
    "\n",
    "Este principio indica que a medida que el número de variables o características aumenta, el número de muestras de entrenamiento que necesitamos para generalizar correctamente aumenta exponencialmente.\n",
    "\n",
    "Así, también se puede controlar la complejidad (varianza), modificando el número de características. Técnicas como selección de características, resultan pues de utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Referencias\n",
    "\n",
    "1. Capítulo 2. An Introduction to Statistical Learning. \n",
    "2. https://en.wikipedia.org/wiki/Bias–variance_tradeoff\n",
    "3. http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
