{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas en clasificación\n",
    "\n",
    "Este notebook, by [Felipe Alonso Atienza](www.linkedin.com/in/felipe-alonso-atienza)\n",
    "\n",
    "En este Notebook vamos analizar distintas métricas y algoritmos sobre un problema de clasificación desbalanceado. \n",
    "\n",
    "## Contenidos\n",
    "\n",
    "1. Análisis exploratorio\n",
    "2. Métricas clasificación\n",
    "3. Comparación clasificadores\n",
    "\n",
    "## Librerías y funciones\n",
    "\n",
    "Lo primero es cargar las librerías y funciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confmat):\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.5)\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.ylabel('true label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Análisis exploratorio\n",
    "\n",
    "Vamos a trabajar con datos de fuga de una compañía telefónica. El objetivo es predecir cuándo los clientes van a abandonar la compañía.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Cargue los datos *churn.csv* y realice un primer análisis de los datos cargados\n",
    "</div>\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Este problema está desbalanceado, calcule el ratio de desbalanceo\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.1 preprocesamiento de variables\n",
    "\n",
    "Si escribimos *data.dtypes* nos indica el tipo de las variables de nuestro dataframe. Vemos que tenemos variables categóricas que tenemos que codificar. \n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Elimine la variable *phone number* y codifique las variables categóricas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Represente el histograma de las variable con distintos colores para cada clase.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pintamos histogramas para cada clase\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "idx_0 =  data['churn'] == 0\n",
    "idx_1 =  data['churn'] == 1\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Correlación entre variables\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Represente el mapa de correlación entre variables\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = np.abs(data.drop(['churn'], axis=1).corr())\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask,vmin = 0.0, vmax=1.0, center=0.5,\n",
    "            linewidths=.1, cmap=\"YlGnBu\", cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = data.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "pairs = np.where(upper>0.95)\n",
    "fx = data.columns[pairs[0]]\n",
    "fy =  data.columns[pairs[1]]\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(22,4))\n",
    "for f1,f2 in zip(fx,fy):\n",
    "    \n",
    "    plt.subplot(1,5,i)\n",
    "    \n",
    "    plt.scatter(data[f1],data[f2], c=data['churn'],cmap=cm_bright, alpha=0.25)\n",
    "    plt.xlabel(f1)\n",
    "    plt.ylabel(f2)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En clasificación, variables correlacionadas no afectan al proceso de clasificación. Sin embargo, dada la correlación extrema y con el objetivo de eliminar variables poco informativas, podemos eliminar algunas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['total day minutes','total eve minutes','total night minutes','total intl minutes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Métricas en clasificación\n",
    "\n",
    "Vamos a representar la matriz de confusión, y a partir de ella calcular distintas métricas. Para ello, comencemos un clasificador sencillo: regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# preparamos los datos\n",
    "\n",
    "columns_to_drop.append('churn')\n",
    "features = data.columns.drop(columns_to_drop)\n",
    "\n",
    "X = data[features].as_matrix()\n",
    "y = data['churn'].as_matrix()\n",
    "\n",
    "\n",
    "# PASO 1:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xs_train = scaler.transform(X_train)\n",
    "Xs_test  = scaler.transform(X_test)\n",
    "\n",
    "print('Datos train: ', Xs_train.shape)\n",
    "print('Datos test:  ', Xs_test.shape)\n",
    "\n",
    "print('Propocion train:%0.3f'%np.mean(y_train))\n",
    "print('Propocion test: %0.3f'%np.mean(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Matriz de confusión y métricas\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Ajuste un algoritmo de regresión logística sobre el conjunto de entrenamiento con $C = 1$. Calcule la predicción para el conjunto de entrenamiento (*y_pred*).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confmat = confusion_matrix(y_train,y_pred)\n",
    "plot_confusion_matrix(confmat)\n",
    "\n",
    "# Podemos acceder a los valores de la matriz\n",
    "tn, fp, fn, tp = confusion_matrix(y_train,y_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: A partir de las TP, TN, FP, FN, calcula las siguiente métricas: SEN, ESP, PPV, FSC, ACC.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Calcula las métricas de performance en el conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = lr.predict(Xs_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Representa el histograma de probabilidad estimada *y_prob* para el conjunto de test. Representa de distinto color cada una de las clases. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = lr.predict_proba(Xs_test)[:,1]\n",
    "\n",
    "idx_0 = (y_test==0)\n",
    "idx_1 = (y_test==1)\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a representar la curva ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "ejex, ejey, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(ejex, ejey)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ejex, ejey, color='darkorange',lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=(0.6, 0.6, 0.6), linestyle='--')\n",
    "plt.plot([0, 0, 1],[0, 1, 1],lw=2, linestyle=':',color='black',label='Clasificador perfecto')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.xlabel('FPR (1-ESP)')\n",
    "plt.ylabel('SEN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Comparación clasificadores\n",
    "\n",
    "Vamos a comparar los siguientes clasificadores: \n",
    "\n",
    "* Regresión logística\n",
    "* Árboles de decisión\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Calcule los parámetros libres óptimos para cada clasificador. Ajuste un modelo con dichos parámetros y compare las métricas obtenidas con cada uno de ellos\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Regresión logística\n",
    "\n",
    "Hemos visto que este algoritmo está sesgado hacia la clase mayoritoria. Para compensar esta situación, podemos asignar pesos distintos a los errores cometidos en cada una de las clases, a través del parámetro [*class_weight*](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "Además, podemos trabajar con distintas [métricas](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) a la hora de optimizar los parámetros libres. Para conjuntos desbalancedados es adecuada:\n",
    "\n",
    "* 'f1': F1-score, compromiso entre SEN, y PPV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vectorC = np.logspace(-3,3,21)\n",
    "param_grid = {'C': vectorC }\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(random_state=0, class_weight='balanced'),\n",
    "                    scoring='f1', \n",
    "                    param_grid=param_grid, \n",
    "                    cv = 10)\n",
    "\n",
    "grid.fit(Xs_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = grid.cv_results_['mean_test_score']\n",
    "std_scores = grid.cv_results_['std_test_score']\n",
    "plt.errorbar(np.log10(vectorC),scores,yerr=std_scores, fmt='o-',ecolor='g')\n",
    "plt.xlabel('log(C)',fontsize=16)\n",
    "plt.ylabel('10-Fold MSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Copt = grid.best_params_['C']\n",
    "\n",
    "lr = LogisticRegression(random_state=0, C = Copt, class_weight='balanced').fit(Xs_train,y_train)\n",
    "y_pred = lr.predict(Xs_test)\n",
    "\n",
    "confmat_test  = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(confmat_test)\n",
    "calcula_metricas(confmat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = lr.predict_proba(Xs_test)[:,1]\n",
    "\n",
    "idx_0 = (y_test==0)\n",
    "idx_1 = (y_test==1)\n",
    "\n",
    "# your code here\n",
    "plt.hist(y_prob[idx_0], normed = 1, label = 'y=0')\n",
    "plt.hist(y_prob[idx_1], normed = 1, facecolor = 'r',alpha=0.6, label = 'y=1')\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Compare el resultado con respecto a entrenar maximizando *accuracy* y sin balancear las clases.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Una vez fijados los parámetros libres, represente la curva ROC. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Árboles de decisión\n",
    "\n",
    "Entrenamos ahora un árbol de decisión. Otra ventaja adicional de los árboles es que por su construcción hace frente al desbalanceo de las clases.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Entrena un árbol de decisión y calcula las métricas obtenidas en el conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "maxDepth = range(1,15)\n",
    "param_grid = {'max_depth': maxDepth }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Visualiza el árbol de decisión entrenado para comprender las predicciones realizadas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(tree, out_file=None, \n",
    "                         feature_names=features,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Random Forest\n",
    "\n",
    "Comprobemos prestaciones para un algoritmo de Random Forest.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Entrena un algoritmo de Random Forest y calcula las métricas obtenidas en el conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# grid search\n",
    "maxDepth   = range(1,15)\n",
    "param_grid = {'max_depth': maxDepth}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**@home: Entrena una SVM y Boosted Trees\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
